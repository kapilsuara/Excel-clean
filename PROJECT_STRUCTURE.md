# Excel Data Cleaner - Project Structure

## 📁 File Organization

The project has been refactored into a modular structure with the following files:

### 🚀 Entry Point
- **`app.py`** - Main Streamlit application entry point
  - Run with: `streamlit run app.py`
  - Contains the UI layout and user interaction logic
  - Manages session state and file uploads
  - Renders the chatbot interface

### 🔧 Core Modules

1. **`config.py`** - Configuration and settings
   - API keys management
   - Application settings
   - Logging configuration
   - File processing limits

2. **`llm_service.py`** - AI/LLM integration
   - Anthropic Claude API integration
   - API key validation
   - Unit standardization with AI
   - Natural language data manipulation
   - AI-powered cleaning suggestions

3. **`excel_processor.py`** - Excel file processing
   - Excel file repair and handling
   - Merged cells processing
   - Hidden rows/columns handling
   - Text cleaning functions
   - Date detection and conversion
   - Numeric column cleaning
   - Outlier detection
   - Column name standardization

4. **`data_analyzer.py`** - Data analysis and metadata
   - Dataset metadata generation
   - Data quality scoring
   - Pattern detection
   - Statistical summaries
   - Data quality metrics
   - Code extraction from AI suggestions

5. **`cleaning_functions.py`** - Main cleaning orchestration
   - `clean_excel_basic()` - Basic cleaning without AI
   - `clean_excel_with_analysis()` - Cleaning with AI analysis
   - `process_all_sheets()` - Multi-sheet processing
   - Coordinates all cleaning operations

### 📊 Original File (for reference)
- **`main.py`** - Original monolithic file (kept for backward compatibility)

## 🏗️ Architecture

```
User Interface (app.py)
        ↓
Cleaning Functions (cleaning_functions.py)
        ↓
    ┌───┴───┐
    ↓       ↓
Excel      Data
Processor  Analyzer
    ↓       ↓
    └───┬───┘
        ↓
   LLM Service
   (AI Integration)
```

## 🚦 How to Run

1. **Install dependencies:**
   ```bash
   pip install streamlit pandas openpyxl numpy anthropic python-dotenv
   ```

2. **Set up API key:**
   - Create a `.env` file in the project root
   - Add: `ANTHROPIC_API_KEY=your_api_key_here`

3. **Run the application:**
   ```bash
   streamlit run app.py
   ```

## 🔄 Data Flow

1. User uploads Excel file through `app.py`
2. File is processed by `cleaning_functions.py`
3. Excel-specific issues handled by `excel_processor.py`
4. Data analysis performed by `data_analyzer.py`
5. AI suggestions generated by `llm_service.py` (if API key available)
6. Cleaned data returned to UI for display/download

## 🎯 Key Features

- **Modular Design**: Easy to maintain and extend
- **AI Integration**: Optional Claude AI for advanced analysis
- **Comprehensive Cleaning**: Handles various data quality issues
- **Fixed Chatbot**: Natural language data manipulation
- **Multi-sheet Support**: Process entire workbooks
- **Quality Metrics**: Data quality scoring and reporting

## 📝 Notes

- The entry point is **`app.py`** - this is the file you run with Streamlit
- All configuration is centralized in `config.py`
- The modular structure makes it easy to:
  - Add new cleaning functions
  - Integrate different LLM providers
  - Extend analysis capabilities
  - Maintain and debug code